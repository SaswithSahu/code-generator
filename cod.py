
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
import os
import tempfile
import subprocess


load_dotenv()


gemini_model = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    temperature=0.7,
    max_tokens=1000,
)

gen_code_template = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant that writes clean and well-commented code."),
    ("user", "Write a {language} code to {task}. Please ensure the code is efficient and follows best practices. Don't give any explanation, just give the code."),
])

explain_code_template = ChatPromptTemplate.from_messages([
    ("system", "You are a programming tutor. Explain the given code step by step in a clear and easy-to-understand manner."),
    ("user", "Explain this {language} code:\n\n{code}"),
])


st.set_page_config(page_title="Gemini Code Generator", page_icon="ü§ñ")
st.title("üí° Gemini Code Generator")
st.markdown("Enter a coding task and get code generated by Gemini AI.")


language = st.selectbox("Select Language", ["Python", "JavaScript", "C++", "Java"])
task = st.text_area("What should the code do?", placeholder="e.g., add two numbers, sort a list...")
test_input_text = st.text_area("Enter test cases (each input on a new line):", "3 5\n10 20\n7 8")


if "generated_code" not in st.session_state:
    st.session_state.generated_code = ""

if st.button("Generate Code") and task:
    with st.spinner("Generating code..."):
        prompt = gen_code_template.format_messages(language=language, task=task)
        response = gemini_model.invoke(prompt)
        st.session_state.generated_code = response.content
        st.markdown("### ü§ñ Gemini Output:")
        st.code(st.session_state.generated_code, language=language.lower())

if st.session_state.generated_code:
    st.markdown("### üõ† What do you want to do next?")
    col1, col2 = st.columns(2)

    with col1:
        if st.button("üìò Explain Code"):
            with st.spinner("Explaining the code..."):
                explain_prompt = explain_code_template.format_messages(language=language, code=st.session_state.generated_code)
                explanation = gemini_model.invoke(explain_prompt)
                st.markdown("### üìñ Code Explanation:")
                st.markdown(explanation.content)

    with col2:
        if language == "Python" and st.button("‚ñ∂Ô∏è Execute Code"):
            with st.spinner("Running code on test cases..."):
                try:
                    # Save code to temporary file
                    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as temp:
                        temp.write(st.session_state.generated_code)
                        temp_path = temp.name

                    # Split user input test cases
                    test_cases = test_input_text.strip().split("\n")

                    # Run code for each test case and capture output
                    for i, input_data in enumerate(test_cases, 1):
                        result = subprocess.run(["python", temp_path], input=input_data.encode(), capture_output=True, timeout=5)
                        st.markdown(f"**Test Case {i}**")
                        st.markdown(f"**Input:** `{input_data}`")
                        st.markdown(f"**Output:** \n```{result.stdout.decode().strip()}```")
                except Exception as e:
                    st.error(f"‚ùå Error during execution: {e}")
